{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa5cd29-6c55-4c2e-a69e-e7446b9b02e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Write a Python code to implement the KNN classifier algorithm on load_iris dataset in\n",
    "sklearn.datasets.\n",
    "\n",
    "\n",
    "ANS-1\n",
    "\n",
    "\n",
    "\n",
    "Sure, here's a Python code to implement the KNN classifier algorithm on the `load_iris` dataset from `sklearn.datasets`:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features to have mean=0 and variance=1\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the KNN classifier with k=3 (you can change the value of k as needed)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generate a classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "```\n",
    "\n",
    "In this code, we first load the iris dataset and split it into training and testing sets. Then, we standardize the features to have mean=0 and variance=1 using `StandardScaler`. Next, we initialize the KNN classifier with k=3 (you can change the value of `n_neighbors` to adjust the k value). We then train the KNN classifier on the training data and make predictions on the test data. Finally, we calculate the accuracy of the classifier, generate a classification report, and print the confusion matrix to evaluate the model's performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q2. Write a Python code to implement the KNN regressor algorithm on load_boston dataset in\n",
    "sklearn.datasets.\n",
    "\n",
    "\n",
    "\n",
    "ANS-2\n",
    "\n",
    "\n",
    "\n",
    "Sure, here's a Python code to implement the KNN regressor algorithm on the `load_boston` dataset from `sklearn.datasets`:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the Boston dataset\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features to have mean=0 and variance=1\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the KNN regressor with k=5 (you can change the value of k as needed)\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the regressor on the training data\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error and R-squared score of the regressor\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared score:\", r2)\n",
    "```\n",
    "\n",
    "In this code, we first load the Boston dataset and split it into training and testing sets. Then, we standardize the features to have mean=0 and variance=1 using `StandardScaler`. Next, we initialize the KNN regressor with k=5 (you can change the value of `n_neighbors` to adjust the k value). We then train the KNN regressor on the training data and make predictions on the test data. Finally, we calculate the mean squared error and R-squared score of the regressor to evaluate its performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q3. Write a Python code snippet to find the optimal value of K for the KNN classifier algorithm using\n",
    "cross-validation on load_iris dataset in sklearn.datasets.\n",
    "\n",
    "\n",
    "\n",
    "ANS-3\n",
    "\n",
    "\n",
    "\n",
    "To find the optimal value of K for the KNN classifier algorithm using cross-validation on the `load_iris` dataset from `sklearn.datasets`, you can use the `GridSearchCV` function from `sklearn.model_selection`. `GridSearchCV` allows you to perform an exhaustive search over specified parameter values and find the best hyperparameter using cross-validation. Here's a Python code snippet to achieve this:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features to have mean=0 and variance=1\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the range of K values to search\n",
    "k_values = np.arange(1, 21)  # You can adjust this range as needed\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Create a dictionary with the hyperparameters to tune\n",
    "param_grid = {'n_neighbors': k_values}\n",
    "\n",
    "# Initialize GridSearchCV with the KNN classifier and the parameter grid\n",
    "grid_search = GridSearchCV(knn_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform the grid search to find the best K value using cross-validation\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best K value and its corresponding accuracy score\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"Best K value:\", best_k)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "```\n",
    "\n",
    "In this code, we first load the iris dataset and split it into training and testing sets. Then, we standardize the features using `StandardScaler`. Next, we define the range of K values (in this case, from 1 to 20) that we want to search over. We then initialize the KNN classifier and create a dictionary with the hyperparameters to tune, where `n_neighbors` is the hyperparameter representing K. We use `GridSearchCV` with 5-fold cross-validation (`cv=5`) to perform an exhaustive search over the specified K values and find the best K value based on the accuracy metric.\n",
    "\n",
    "After performing the grid search, we extract the best K value and its corresponding accuracy score. The best K value is the one that results in the highest accuracy on the training data. You can use this optimal K value to train the final KNN classifier and evaluate its performance on the test data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q4. Implement the KNN regressor algorithm with feature scaling on load_boston dataset in\n",
    "sklearn.datasets.\n",
    "\n",
    "\n",
    "\n",
    "ANS-4\n",
    "\n",
    "\n",
    "To implement the KNN regressor algorithm with feature scaling on the `load_boston` dataset from `sklearn.datasets`, we need to follow these steps:\n",
    "\n",
    "1. Load the dataset.\n",
    "2. Split the data into training and testing sets.\n",
    "3. Perform feature scaling on the features.\n",
    "4. Initialize the KNN regressor.\n",
    "5. Train the regressor on the training data.\n",
    "6. Make predictions on the test data.\n",
    "7. Evaluate the performance of the regressor using metrics such as mean squared error (MSE) and R-squared score.\n",
    "\n",
    "Here's the Python code to achieve this:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the Boston dataset\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features to have mean=0 and variance=1\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the KNN regressor with k=5 (you can change the value of k as needed)\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the regressor on the training data\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error and R-squared score of the regressor\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared score:\", r2)\n",
    "```\n",
    "\n",
    "In this code, we first load the Boston dataset and split it into training and testing sets. Then, we perform feature scaling on the features using `StandardScaler`. Next, we initialize the KNN regressor with k=5 (you can change the value of `n_neighbors` to adjust the k value). We then train the KNN regressor on the training data and make predictions on the test data. Finally, we calculate the mean squared error and R-squared score to evaluate the performance of the regressor.\n",
    "\n",
    "Note: Feature scaling is crucial for KNN algorithms because it relies on the distance between data points. Standardizing the features helps to avoid any bias caused by features with larger scales dominating the distance calculations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q5. Write a Python code snippet to implement the KNN classifier algorithm with weighted voting on\n",
    "load_iris dataset in sklearn.datasets.\n",
    "\n",
    "\n",
    "\n",
    "ANS-5\n",
    "\n",
    "\n",
    "\n",
    "To implement the KNN classifier algorithm with weighted voting on the `load_iris` dataset from `sklearn.datasets`, we need to follow these steps:\n",
    "\n",
    "1. Load the dataset.\n",
    "2. Split the data into training and testing sets.\n",
    "3. Perform any necessary feature scaling (not required for all distance metrics).\n",
    "4. Initialize the KNN classifier with weighted voting.\n",
    "5. Train the classifier on the training data.\n",
    "6. Make predictions on the test data.\n",
    "7. Evaluate the performance of the classifier using metrics such as accuracy, classification report, and confusion matrix.\n",
    "\n",
    "Here's the Python code to implement the KNN classifier with weighted voting:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Optional: Standardize the features to have mean=0 and variance=1\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the KNN classifier with weighted voting\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
    "\n",
    "# Train the classifier on the training data\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generate a classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "```\n",
    "\n",
    "In this code, we first load the iris dataset and split it into training and testing sets. Optionally, we perform feature scaling using `StandardScaler`, but it's worth noting that weighted voting does not require feature scaling, as it already takes into account the distance between data points.\n",
    "\n",
    "Next, we initialize the KNN classifier with weighted voting by setting the `weights` parameter to `'distance'`. This means that the vote of each neighbor is weighted based on its distance to the query point, with closer neighbors having more influence on the prediction.\n",
    "\n",
    "We then train the KNN classifier on the training data and make predictions on the test data. Finally, we calculate the accuracy of the classifier and generate a classification report and confusion matrix to evaluate its performance.\n",
    "\n",
    "By using weighted voting, the KNN classifier gives more importance to closer neighbors, which can be particularly useful when data points that are closer to the query point are more likely to be similar and relevant for making accurate predictions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q6. Implement a function to standardise the features before applying KNN classifier.\n",
    "\n",
    "\n",
    "\n",
    "ANS-6\n",
    "\n",
    "\n",
    "\n",
    "To standardize the features before applying the KNN classifier, you can create a function that takes the feature matrix X as input and returns the standardized feature matrix. The standardization process involves subtracting the mean from each feature and dividing by the standard deviation, so that the features have mean=0 and variance=1.\n",
    "\n",
    "Here's a Python function to perform feature standardization:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def standardize_features(X):\n",
    "    \"\"\"\n",
    "    Standardize the features in the feature matrix X.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy array): Feature matrix of shape (n_samples, n_features).\n",
    "    \n",
    "    Returns:\n",
    "    X_standardized (numpy array): Standardized feature matrix of shape (n_samples, n_features).\n",
    "    \"\"\"\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    X_standardized = (X - mean) / std\n",
    "    return X_standardized\n",
    "```\n",
    "\n",
    "You can use this function to standardize the features before applying the KNN classifier:\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features in the training and testing sets\n",
    "X_train_standardized = standardize_features(X_train)\n",
    "X_test_standardized = standardize_features(X_test)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the classifier on the standardized training data\n",
    "knn_classifier.fit(X_train_standardized, y_train)\n",
    "\n",
    "# Make predictions on the standardized test data\n",
    "y_pred = knn_classifier.predict(X_test_standardized)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "```\n",
    "\n",
    "In this code, we first define the `standardize_features` function that takes a feature matrix X as input, computes the mean and standard deviation for each feature, and then standardizes the features by subtracting the mean and dividing by the standard deviation. We then use this function to standardize the features in the training and testing sets before applying the KNN classifier. This ensures that the features have mean=0 and variance=1, making the KNN algorithm more effective, especially if it uses distance-based metrics like Euclidean distance or Manhattan distance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q7. Write a Python function to calculate the euclidean distance between two points.\n",
    "\n",
    "\n",
    "\n",
    "ANS-7\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
